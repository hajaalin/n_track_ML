{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/group/lmu/software/Miniconda3/py38_4.12.0/envs/tsc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 1.1.1\n",
      "sktime 0.10.1\n",
      "Loaded data shape: (8398, 17)\n",
      "Index(['file', 'serum', 'D', 'A', 'P', 'Dist', 't', 'dt'], dtype='object')\n",
      "X.shape: (289, 6, 28)\n",
      "X.shape: (289, 28, 6)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['MPLCONFIGDIR'] = \"/wrk-vakka/users/hajaalin/tmp_mplconfigdir\"\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import shap\n",
    "import sys\n",
    "\n",
    "from etl_tsc import load_data\n",
    "from utility import parse_config\n",
    "\n",
    "paths = \"/proj/hajaalin/Projects/n_track_ML/scripts/tsc/paths.yml\"\n",
    "paths = parse_config(paths)\n",
    "    \n",
    "# add InceptionTime source to Python path\n",
    "src_inceptiontime = paths[\"src\"][\"inceptiontime\"]\n",
    "sys.path.insert(1, src_inceptiontime)\n",
    "from cv_inceptiontime import inceptiontime_cv_repeat, get_standard_scaling, apply_standard_scaling\n",
    "from utils.utils import readucr\n",
    "\n",
    "# read the data \n",
    "data_dir = paths[\"data\"][\"dir\"]\n",
    "raw_data_file = paths[\"data\"][\"raw_data_file\"]\n",
    "fset = \"all\"\n",
    "X, y, groups, features, datam, datan = load_data(Path(data_dir) / raw_data_file, fset, debug=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionTime input example\n",
    "Check the input format based on test data (https://github.com/hfawaz/InceptionTime#data). \n",
    "\n",
    "The order is (instance, timestep, feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_ucr: /proj/hajaalin/Projects/UCR_TS_Archive_2015/InlineSkate/InlineSkate_TRAIN\n",
      "x_train.shape: (100, 1882)\n",
      "y_train.shape: (100,)\n",
      "x_train.shape: (100, 1882, 1)\n"
     ]
    }
   ],
   "source": [
    "file_name = \\\n",
    "'/proj/hajaalin/Projects/UCR_TS_Archive_2015/InlineSkate/InlineSkate_TRAIN'\n",
    "print('test_ucr: ' + file_name)\n",
    "x_train, y_train = readucr(file_name)\n",
    "print('x_train.shape: ' + str(x_train.shape))\n",
    "print('y_train.shape: ' + str(y_train.shape))\n",
    "# https://github.com/hajaalin/InceptionTime/blob/d518ebe04c4404e49bdb056aa4aa00ea6ba9bd26/main.py#L35\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    # add a dimension to make it multivariate with one dimension\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "print('x_train.shape: ' + str(x_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data loading intermediates\n",
    "## Multi-index dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>serum</th>\n",
       "      <th>D</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>Dist</th>\n",
       "      <th>t</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">210521_guide_1514i.sld_-_1514_i10_t35__0</th>\n",
       "      <th>2</th>\n",
       "      <td>210521_guide_1514i.sld_-_1514_i10_t35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117854</td>\n",
       "      <td>301.848958</td>\n",
       "      <td>18.558761</td>\n",
       "      <td>1.773953</td>\n",
       "      <td>3.131322</td>\n",
       "      <td>1.233874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>210521_guide_1514i.sld_-_1514_i10_t35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366152</td>\n",
       "      <td>301.458175</td>\n",
       "      <td>18.709589</td>\n",
       "      <td>1.343691</td>\n",
       "      <td>-1.903313</td>\n",
       "      <td>-5.034635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210521_guide_1514i.sld_-_1514_i10_t35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239324</td>\n",
       "      <td>300.937131</td>\n",
       "      <td>18.634175</td>\n",
       "      <td>1.526075</td>\n",
       "      <td>0.431272</td>\n",
       "      <td>2.334585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>210521_guide_1514i.sld_-_1514_i10_t35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187754</td>\n",
       "      <td>301.492454</td>\n",
       "      <td>18.538193</td>\n",
       "      <td>1.435976</td>\n",
       "      <td>-3.092591</td>\n",
       "      <td>-3.523863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>210521_guide_1514i.sld_-_1514_i10_t35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>301.979219</td>\n",
       "      <td>18.565617</td>\n",
       "      <td>1.441959</td>\n",
       "      <td>-0.843499</td>\n",
       "      <td>2.249091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 file  \\\n",
       "fp                                       frame                                          \n",
       "210521_guide_1514i.sld_-_1514_i10_t35__0 2      210521_guide_1514i.sld_-_1514_i10_t35   \n",
       "                                         3      210521_guide_1514i.sld_-_1514_i10_t35   \n",
       "                                         4      210521_guide_1514i.sld_-_1514_i10_t35   \n",
       "                                         5      210521_guide_1514i.sld_-_1514_i10_t35   \n",
       "                                         6      210521_guide_1514i.sld_-_1514_i10_t35   \n",
       "\n",
       "                                                serum         D           A  \\\n",
       "fp                                       frame                                \n",
       "210521_guide_1514i.sld_-_1514_i10_t35__0 2          0  0.117854  301.848958   \n",
       "                                         3          0  0.366152  301.458175   \n",
       "                                         4          0  0.239324  300.937131   \n",
       "                                         5          0  0.187754  301.492454   \n",
       "                                         6          0  0.094312  301.979219   \n",
       "\n",
       "                                                        P      Dist         t  \\\n",
       "fp                                       frame                                  \n",
       "210521_guide_1514i.sld_-_1514_i10_t35__0 2      18.558761  1.773953  3.131322   \n",
       "                                         3      18.709589  1.343691 -1.903313   \n",
       "                                         4      18.634175  1.526075  0.431272   \n",
       "                                         5      18.538193  1.435976 -3.092591   \n",
       "                                         6      18.565617  1.441959 -0.843499   \n",
       "\n",
       "                                                      dt  \n",
       "fp                                       frame            \n",
       "210521_guide_1514i.sld_-_1514_i10_t35__0 2      1.233874  \n",
       "                                         3     -5.034635  \n",
       "                                         4      2.334585  \n",
       "                                         5     -3.523863  \n",
       "                                         6      2.249091  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>serum</th>\n",
       "      <th>D</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>Dist</th>\n",
       "      <th>t</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2     210521_guide_1514i.sld_-_1514_i10_t35\n",
       "3 ...</td>\n",
       "      <td>2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     ...</td>\n",
       "      <td>2     0.117854\n",
       "3     0.366152\n",
       "4     0.239324\n",
       "5...</td>\n",
       "      <td>2     301.848958\n",
       "3     301.458175\n",
       "4     300.93...</td>\n",
       "      <td>2     18.558761\n",
       "3     18.709589\n",
       "4     18.63417...</td>\n",
       "      <td>2     1.773953\n",
       "3     1.343691\n",
       "4     1.526075\n",
       "5...</td>\n",
       "      <td>2     3.131322\n",
       "3    -1.903313\n",
       "4     0.431272\n",
       "5...</td>\n",
       "      <td>2     1.233874\n",
       "3    -5.034635\n",
       "4     2.334585\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2     210521_guide_1514i.sld_-_1514_i10_t35\n",
       "3 ...</td>\n",
       "      <td>2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     ...</td>\n",
       "      <td>2     0.216666\n",
       "3     0.094942\n",
       "4     0.111515\n",
       "5...</td>\n",
       "      <td>2     301.848958\n",
       "3     301.458175\n",
       "4     300.93...</td>\n",
       "      <td>2     18.558761\n",
       "3     18.709589\n",
       "4     18.63417...</td>\n",
       "      <td>2     4.449394\n",
       "3     4.513221\n",
       "4     4.391940\n",
       "5...</td>\n",
       "      <td>2     2.197163\n",
       "3     1.830648\n",
       "4    -1.163123\n",
       "5...</td>\n",
       "      <td>2     3.695569\n",
       "3    -0.366515\n",
       "4    -2.993771\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2     210521_guide_1514i.sld_-_1514_i1_t0\n",
       "3   ...</td>\n",
       "      <td>2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...</td>\n",
       "      <td>2     0.178829\n",
       "3     0.157572\n",
       "4     0.192724\n",
       "5...</td>\n",
       "      <td>2     512.165585\n",
       "3     512.384972\n",
       "4     511.99...</td>\n",
       "      <td>2     19.573425\n",
       "3     19.498011\n",
       "4     19.52543...</td>\n",
       "      <td>2     8.067957\n",
       "3     8.165918\n",
       "4     7.983479\n",
       "5...</td>\n",
       "      <td>2     0.297310\n",
       "3     2.660113\n",
       "4     0.903404\n",
       "5...</td>\n",
       "      <td>2    -2.646482\n",
       "3     2.362802\n",
       "4    -1.756709\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2     210521_guide_1514i.sld_-_1514_i1_t0\n",
       "3   ...</td>\n",
       "      <td>2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...</td>\n",
       "      <td>2     0.047684\n",
       "3     0.064591\n",
       "4     0.193787\n",
       "5...</td>\n",
       "      <td>2     512.165585\n",
       "3     512.384972\n",
       "4     511.99...</td>\n",
       "      <td>2     19.573425\n",
       "3     19.498011\n",
       "4     19.52543...</td>\n",
       "      <td>2     7.585871\n",
       "3     7.720695\n",
       "4     7.894178\n",
       "5...</td>\n",
       "      <td>2     1.016186\n",
       "3    -0.930621\n",
       "4    -2.030110\n",
       "5...</td>\n",
       "      <td>2     3.653593\n",
       "3    -1.946807\n",
       "4    -1.099489\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2     210521_guide_1514i.sld_-_1514_i2_t0_\n",
       "3  ...</td>\n",
       "      <td>2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...</td>\n",
       "      <td>2     0.128653\n",
       "3     0.008553\n",
       "4     0.026992\n",
       "5...</td>\n",
       "      <td>2     278.881891\n",
       "3     278.792765\n",
       "4     278.29...</td>\n",
       "      <td>2     14.781193\n",
       "3     14.788049\n",
       "4     14.76748...</td>\n",
       "      <td>2     1.855279\n",
       "3     1.882042\n",
       "4     1.883155\n",
       "5...</td>\n",
       "      <td>2     1.932570\n",
       "3    -0.246117\n",
       "4     1.314753\n",
       "5...</td>\n",
       "      <td>2     3.544357\n",
       "3    -2.178687\n",
       "4     1.560871\n",
       "5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  2     210521_guide_1514i.sld_-_1514_i10_t35\n",
       "3 ...   \n",
       "1  2     210521_guide_1514i.sld_-_1514_i10_t35\n",
       "3 ...   \n",
       "2  2     210521_guide_1514i.sld_-_1514_i1_t0\n",
       "3   ...   \n",
       "3  2     210521_guide_1514i.sld_-_1514_i1_t0\n",
       "3   ...   \n",
       "4  2     210521_guide_1514i.sld_-_1514_i2_t0_\n",
       "3  ...   \n",
       "\n",
       "                                               serum  \\\n",
       "0  2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     ...   \n",
       "1  2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     ...   \n",
       "2  2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...   \n",
       "3  2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...   \n",
       "4  2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     ...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  2     0.117854\n",
       "3     0.366152\n",
       "4     0.239324\n",
       "5...   \n",
       "1  2     0.216666\n",
       "3     0.094942\n",
       "4     0.111515\n",
       "5...   \n",
       "2  2     0.178829\n",
       "3     0.157572\n",
       "4     0.192724\n",
       "5...   \n",
       "3  2     0.047684\n",
       "3     0.064591\n",
       "4     0.193787\n",
       "5...   \n",
       "4  2     0.128653\n",
       "3     0.008553\n",
       "4     0.026992\n",
       "5...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  2     301.848958\n",
       "3     301.458175\n",
       "4     300.93...   \n",
       "1  2     301.848958\n",
       "3     301.458175\n",
       "4     300.93...   \n",
       "2  2     512.165585\n",
       "3     512.384972\n",
       "4     511.99...   \n",
       "3  2     512.165585\n",
       "3     512.384972\n",
       "4     511.99...   \n",
       "4  2     278.881891\n",
       "3     278.792765\n",
       "4     278.29...   \n",
       "\n",
       "                                                   P  \\\n",
       "0  2     18.558761\n",
       "3     18.709589\n",
       "4     18.63417...   \n",
       "1  2     18.558761\n",
       "3     18.709589\n",
       "4     18.63417...   \n",
       "2  2     19.573425\n",
       "3     19.498011\n",
       "4     19.52543...   \n",
       "3  2     19.573425\n",
       "3     19.498011\n",
       "4     19.52543...   \n",
       "4  2     14.781193\n",
       "3     14.788049\n",
       "4     14.76748...   \n",
       "\n",
       "                                                Dist  \\\n",
       "0  2     1.773953\n",
       "3     1.343691\n",
       "4     1.526075\n",
       "5...   \n",
       "1  2     4.449394\n",
       "3     4.513221\n",
       "4     4.391940\n",
       "5...   \n",
       "2  2     8.067957\n",
       "3     8.165918\n",
       "4     7.983479\n",
       "5...   \n",
       "3  2     7.585871\n",
       "3     7.720695\n",
       "4     7.894178\n",
       "5...   \n",
       "4  2     1.855279\n",
       "3     1.882042\n",
       "4     1.883155\n",
       "5...   \n",
       "\n",
       "                                                   t  \\\n",
       "0  2     3.131322\n",
       "3    -1.903313\n",
       "4     0.431272\n",
       "5...   \n",
       "1  2     2.197163\n",
       "3     1.830648\n",
       "4    -1.163123\n",
       "5...   \n",
       "2  2     0.297310\n",
       "3     2.660113\n",
       "4     0.903404\n",
       "5...   \n",
       "3  2     1.016186\n",
       "3    -0.930621\n",
       "4    -2.030110\n",
       "5...   \n",
       "4  2     1.932570\n",
       "3    -0.246117\n",
       "4     1.314753\n",
       "5...   \n",
       "\n",
       "                                                  dt  \n",
       "0  2     1.233874\n",
       "3    -5.034635\n",
       "4     2.334585\n",
       "5...  \n",
       "1  2     3.695569\n",
       "3    -0.366515\n",
       "4    -2.993771\n",
       "5...  \n",
       "2  2    -2.646482\n",
       "3     2.362802\n",
       "4    -1.756709\n",
       "5...  \n",
       "3  2     3.653593\n",
       "3    -1.946807\n",
       "4    -1.099489\n",
       "5...  \n",
       "4  2     3.544357\n",
       "3    -2.178687\n",
       "4     1.560871\n",
       "5...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy array\n",
    "Check that order is (instance, timestep, feature) as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 28, 6)\n",
      "[[1.17853868e-01 3.01848958e+02 1.85587610e+01]\n",
      " [3.66152200e-01 3.01458175e+02 1.87095895e+01]\n",
      " [2.39324351e-01 3.00937131e+02 1.86341752e+01]\n",
      " [1.87753582e-01 3.01492454e+02 1.85381935e+01]\n",
      " [9.43115227e-02 3.01979219e+02 1.85656168e+01]\n",
      " [2.95413433e-01 3.02054633e+02 1.86136077e+01]\n",
      " [5.30514119e-01 3.01746120e+02 1.86410311e+01]\n",
      " [3.18407073e-01 3.01794111e+02 1.86958778e+01]\n",
      " [2.64851734e-01 3.01979219e+02 1.87370128e+01]\n",
      " [3.83052910e-01 3.02219173e+02 1.86890220e+01]\n",
      " [9.66055800e-02 3.01218220e+02 1.86478869e+01]\n",
      " [7.67474198e-02 3.01773544e+02 1.87027336e+01]\n",
      " [2.52588090e-01 3.01636427e+02 1.86615986e+01]\n",
      " [5.79309723e-02 3.01382761e+02 1.86204636e+01]\n",
      " [2.79227669e-01 3.01595292e+02 1.86547428e+01]\n",
      " [4.05124575e-01 3.01163374e+02 1.85998960e+01]\n",
      " [4.86220811e-01 3.01423896e+02 1.86547428e+01]\n",
      " [1.49985643e-01 3.01547301e+02 1.86890220e+01]\n",
      " [1.87615541e-01 3.01307346e+02 1.86547428e+01]\n",
      " [1.39931581e-01 3.01513022e+02 1.86341752e+01]\n",
      " [2.54295206e-01 3.01094815e+02 1.86341752e+01]\n",
      " [3.18679840e-01 3.01101671e+02 1.86410311e+01]\n",
      " [2.58355145e-01 3.00902852e+02 1.86753103e+01]\n",
      " [9.77054484e-02 3.00724600e+02 1.86204636e+01]\n",
      " [2.42236222e-01 3.00841149e+02 1.86753103e+01]\n",
      " [3.68110310e-01 3.00450366e+02 1.86204636e+01]\n",
      " [3.44074629e-01 3.00265259e+02 1.85793285e+01]\n",
      " [7.70537766e-02 2.99847052e+02 1.86136077e+01]]\n",
      "(74, 28, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1533029366d0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0,:,0:3])\n",
    "print(list_shap_deep[0].shape)\n",
    "plt.plot(X[0,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15333104f9d0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(X[2,:,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289,)\n",
      "[0. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y,), axis=0)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class array onehot encoded\n",
    "Note that ```yoh[1]``` corresponds to the original class array. SHAP values will be computed for both model inputs, the ones corresponding to the original class labels will be in index ```[1]```-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.concatenate((y,), axis=0).reshape(-1, 1))\n",
    "yoh = enc.transform(y.reshape(-1, 1)).toarray()\n",
    "print(yoh[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(289, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "[ 6.86663121e-02  3.57286334e+02  1.72903288e+01  3.42911147e+00\n",
      " -1.78580657e-04 -2.26079082e-03]\n",
      "apply_standard_scaling\n",
      "(289, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(289, 28, 6)\n",
      "[[ 0.87180386 -0.38415371  0.3424533 ]\n",
      " [ 5.27266177 -0.38686164  0.38317421]\n",
      " [ 3.02475564 -0.39047222  0.36281376]\n",
      " [ 2.11071153 -0.38662411  0.33690045]\n",
      " [ 0.4545376  -0.38325107  0.34430425]\n",
      " [ 4.01888266 -0.38272848  0.3572609 ]\n",
      " [ 8.18582453 -0.38486633  0.36466471]\n",
      " [ 4.42642364 -0.38453377  0.37947231]\n",
      " [ 3.47720486 -0.38325107  0.39057801]\n",
      " [ 5.5722112  -0.3815883   0.37762136]\n",
      " [ 0.49519764 -0.38852441  0.36651566]\n",
      " [ 0.14323015 -0.38467629  0.38132326]\n",
      " [ 3.25984313 -0.38562645  0.37021756]\n",
      " [-0.19027395 -0.38738423  0.35911186]\n",
      " [ 3.73200499 -0.38591149  0.36836661]\n",
      " [ 5.96341101 -0.38890447  0.353559  ]\n",
      " [ 7.40076668 -0.38709918  0.36836661]\n",
      " [ 1.4413098  -0.38624405  0.37762136]\n",
      " [ 2.10826489 -0.38790681  0.36836661]\n",
      " [ 1.26311088 -0.38648158  0.36281376]\n",
      " [ 3.29010018 -0.38937955  0.36281376]\n",
      " [ 4.43125816 -0.38933204  0.36466471]\n",
      " [ 3.36205885 -0.39070976  0.37391946]\n",
      " [ 0.51469179 -0.39194496  0.35911186]\n",
      " [ 3.07636586 -0.39113733  0.37391946]\n",
      " [ 5.30736746 -0.39384526  0.35911186]\n",
      " [ 4.88135729 -0.39512797  0.34800615]\n",
      " [ 0.14866004 -0.39802593  0.3572609 ]]\n",
      "(74, 28, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x153302905b20>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean, std = get_standard_scaling(X)\n",
    "print(mean)\n",
    "X_scaled = apply_standard_scaling(X, mean, std)\n",
    "print(X_scaled[0,:,0:3])\n",
    "print(list_shap_deep[0].shape)\n",
    "plt.plot(X_scaled[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 28, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x153301f65520>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(list_shap_deep[0].shape)\n",
    "plt.plot(X_scaled[2,:,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat cross-validation with InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/wrk/group/lmu/projects/n_track_ML/output/shap/shap_inceptiontime/20221207112125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "use_bottleneck=True\n",
    "kernel_size = 20\n",
    "epochs = 20\n",
    "repeats = 2\n",
    "job_name = \"shap_inceptiontime\"\n",
    "job_id = \"1\"\n",
    "now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "save_shap_values = True\n",
    "set_split_random_state = False\n",
    "verbose = True\n",
    "\n",
    "# output folders\n",
    "output_shap = Path(paths[\"output\"][\"shap\"]) / job_name / now\n",
    "output_shap.mkdir(parents=True, exist_ok=True)\n",
    "output_it = Path(paths[\"output\"][\"it\"]) / job_id\n",
    "output_it.mkdir(parents=True, exist_ok=True)\n",
    "output_it = str(output_it) + \"/\"\n",
    "\n",
    "print(output_shap)\n",
    "!ls $output_shap\n",
    "os.listdir(output_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['D', 'A', 'P', 'Dist', 't', 'dt'], dtype='object')\n",
      "input_shape\n",
      "(28, 6)\n",
      "StratifiedGroupKFold(n_splits=4, random_state=None, shuffle=True)\n",
      "repeat: 1/2\n",
      "get_standard_scaling\n",
      "(215, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(215, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(215, 28, 6)\n",
      "check scaled shape\n",
      "(215, 28, 6)\n",
      "(215, 28, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 11:22:34.571233: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 28, 32)       192         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 28, 6)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 28, 32)       3072        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 28, 32)       7168        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 28, 32)       11264       ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 28, 32)       23552       ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 28, 32)       29696       ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 28, 32)       192         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 192)      0           ['conv1d_1[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]',               \n",
      "                                                                  'conv1d_3[0][0]',               \n",
      "                                                                  'conv1d_4[0][0]',               \n",
      "                                                                  'conv1d_5[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 192)     768         ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 28, 192)      0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 28, 32)       6144        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 28, 192)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 28, 32)       3072        ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 28, 32)       7168        ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 28, 32)       11264       ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 28, 32)       23552       ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 28, 32)       29696       ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 192)      0           ['conv1d_8[0][0]',               \n",
      "                                                                  'conv1d_9[0][0]',               \n",
      "                                                                  'conv1d_10[0][0]',              \n",
      "                                                                  'conv1d_11[0][0]',              \n",
      "                                                                  'conv1d_12[0][0]',              \n",
      "                                                                  'conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 192)     768         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 28, 192)      0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 28, 32)       6144        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 28, 192)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 28, 32)       3072        ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 28, 32)       7168        ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 28, 32)       11264       ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 28, 32)       23552       ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 28, 32)       29696       ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 28, 192)      0           ['conv1d_15[0][0]',              \n",
      "                                                                  'conv1d_16[0][0]',              \n",
      "                                                                  'conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_18[0][0]',              \n",
      "                                                                  'conv1d_19[0][0]',              \n",
      "                                                                  'conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 28, 192)      1152        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 192)     768         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 192)     768         ['conv1d_21[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 192)      0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 28, 192)      0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 192)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 28, 32)       6144        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 28, 192)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 28, 32)       3072        ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 28, 32)       7168        ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 28, 32)       11264       ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 28, 32)       23552       ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 28, 32)       29696       ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 28, 192)      0           ['conv1d_23[0][0]',              \n",
      "                                                                  'conv1d_24[0][0]',              \n",
      "                                                                  'conv1d_25[0][0]',              \n",
      "                                                                  'conv1d_26[0][0]',              \n",
      "                                                                  'conv1d_27[0][0]',              \n",
      "                                                                  'conv1d_28[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 192)     768         ['concatenate_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 28, 192)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 28, 32)       6144        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 28, 192)     0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 28, 32)       3072        ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 28, 32)       7168        ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 28, 32)       11264       ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 28, 32)       23552       ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 28, 32)       29696       ['conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 28, 192)      0           ['conv1d_30[0][0]',              \n",
      "                                                                  'conv1d_31[0][0]',              \n",
      "                                                                  'conv1d_32[0][0]',              \n",
      "                                                                  'conv1d_33[0][0]',              \n",
      "                                                                  'conv1d_34[0][0]',              \n",
      "                                                                  'conv1d_35[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 192)     768         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 28, 192)      0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 28, 32)       6144        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 28, 192)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 28, 32)       3072        ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 28, 32)       7168        ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 28, 32)       11264       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 28, 32)       23552       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 28, 32)       29696       ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 28, 192)      0           ['conv1d_37[0][0]',              \n",
      "                                                                  'conv1d_38[0][0]',              \n",
      "                                                                  'conv1d_39[0][0]',              \n",
      "                                                                  'conv1d_40[0][0]',              \n",
      "                                                                  'conv1d_41[0][0]',              \n",
      "                                                                  'conv1d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 28, 192)      36864       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 192)     768         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 28, 192)     768         ['conv1d_43[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 28, 192)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 192)      0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 28, 192)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 192)         0           ['activation_7[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            386         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 7s 101ms/step - loss: 0.8521 - accuracy: 0.5860\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.6234 - accuracy: 0.6558\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.6257 - accuracy: 0.6930\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.5650 - accuracy: 0.7209\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.4311 - accuracy: 0.7953\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.3512 - accuracy: 0.8605\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.3836 - accuracy: 0.8419\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1781 - accuracy: 0.9628\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1251 - accuracy: 0.9628\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1595 - accuracy: 0.9395\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1709 - accuracy: 0.9349\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1065 - accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0714 - accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0952 - accuracy: 0.9674\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0864 - accuracy: 0.9767\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1074 - accuracy: 0.9628\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0503 - accuracy: 0.9860\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.0429 - accuracy: 0.9953\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0654 - accuracy: 0.9814\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0310 - accuracy: 0.9907\n",
      "apply_standard_scaling\n",
      "(74, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(74, 28, 6)\n",
      "5/5 [==============================] - 1s 26ms/step\n",
      "fold_acc 0.5675680.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n",
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(218, 28, 6)\n",
      "check scaled shape\n",
      "(218, 28, 6)\n",
      "(218, 28, 6)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 28, 32)       192         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 28, 6)       0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 28, 32)       3072        ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 28, 32)       7168        ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 28, 32)       11264       ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 28, 32)       23552       ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 28, 32)       29696       ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 28, 32)       192         ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 28, 192)      0           ['conv1d_45[0][0]',              \n",
      "                                                                  'conv1d_46[0][0]',              \n",
      "                                                                  'conv1d_47[0][0]',              \n",
      "                                                                  'conv1d_48[0][0]',              \n",
      "                                                                  'conv1d_49[0][0]',              \n",
      "                                                                  'conv1d_50[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 28, 192)     768         ['concatenate_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 28, 192)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 28, 32)       6144        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 28, 192)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 28, 32)       3072        ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 28, 32)       7168        ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 28, 32)       11264       ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 28, 32)       23552       ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 28, 32)       29696       ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 28, 192)      0           ['conv1d_52[0][0]',              \n",
      "                                                                  'conv1d_53[0][0]',              \n",
      "                                                                  'conv1d_54[0][0]',              \n",
      "                                                                  'conv1d_55[0][0]',              \n",
      "                                                                  'conv1d_56[0][0]',              \n",
      "                                                                  'conv1d_57[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 28, 192)     768         ['concatenate_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 28, 192)      0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 28, 32)       6144        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 28, 192)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, 28, 32)       3072        ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_60 (Conv1D)             (None, 28, 32)       7168        ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_61 (Conv1D)             (None, 28, 32)       11264       ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_62 (Conv1D)             (None, 28, 32)       23552       ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_63 (Conv1D)             (None, 28, 32)       29696       ['conv1d_58[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 28, 192)      0           ['conv1d_59[0][0]',              \n",
      "                                                                  'conv1d_60[0][0]',              \n",
      "                                                                  'conv1d_61[0][0]',              \n",
      "                                                                  'conv1d_62[0][0]',              \n",
      "                                                                  'conv1d_63[0][0]',              \n",
      "                                                                  'conv1d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)             (None, 28, 192)      1152        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 28, 192)     768         ['concatenate_8[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 28, 192)     768         ['conv1d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 28, 192)      0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 28, 192)      0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 28, 192)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)             (None, 28, 32)       6144        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 28, 192)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)             (None, 28, 32)       3072        ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 28, 32)       7168        ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 28, 32)       11264       ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 28, 32)       23552       ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 28, 32)       29696       ['conv1d_66[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_72 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 28, 192)      0           ['conv1d_67[0][0]',              \n",
      "                                                                  'conv1d_68[0][0]',              \n",
      "                                                                  'conv1d_69[0][0]',              \n",
      "                                                                  'conv1d_70[0][0]',              \n",
      "                                                                  'conv1d_71[0][0]',              \n",
      "                                                                  'conv1d_72[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 192)     768         ['concatenate_9[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 28, 192)      0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_73 (Conv1D)             (None, 28, 32)       6144        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 28, 192)     0           ['activation_12[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)             (None, 28, 32)       3072        ['conv1d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 28, 32)       7168        ['conv1d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 28, 32)       11264       ['conv1d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 28, 32)       23552       ['conv1d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 28, 32)       29696       ['conv1d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 28, 192)      0           ['conv1d_74[0][0]',              \n",
      "                                                                  'conv1d_75[0][0]',              \n",
      "                                                                  'conv1d_76[0][0]',              \n",
      "                                                                  'conv1d_77[0][0]',              \n",
      "                                                                  'conv1d_78[0][0]',              \n",
      "                                                                  'conv1d_79[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 28, 192)     768         ['concatenate_10[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 28, 192)      0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_80 (Conv1D)             (None, 28, 32)       6144        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 28, 192)     0           ['activation_13[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_81 (Conv1D)             (None, 28, 32)       3072        ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)             (None, 28, 32)       7168        ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)             (None, 28, 32)       11264       ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 28, 32)       23552       ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 28, 32)       29696       ['conv1d_80[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 28, 32)       6144        ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 28, 192)      0           ['conv1d_81[0][0]',              \n",
      "                                                                  'conv1d_82[0][0]',              \n",
      "                                                                  'conv1d_83[0][0]',              \n",
      "                                                                  'conv1d_84[0][0]',              \n",
      "                                                                  'conv1d_85[0][0]',              \n",
      "                                                                  'conv1d_86[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 28, 192)      36864       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 28, 192)     768         ['concatenate_11[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 28, 192)     768         ['conv1d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 28, 192)      0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 28, 192)      0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 28, 192)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 192)         0           ['activation_15[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            386         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 89ms/step - loss: 0.8854 - accuracy: 0.6101\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.6089 - accuracy: 0.7018\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.6139 - accuracy: 0.7110\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.5620 - accuracy: 0.7018\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.5097 - accuracy: 0.7156\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.5061 - accuracy: 0.7569\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.4770 - accuracy: 0.7615\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.4706 - accuracy: 0.7752\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.4228 - accuracy: 0.8349\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.3348 - accuracy: 0.8578\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.2522 - accuracy: 0.8991\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1464 - accuracy: 0.9633\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1451 - accuracy: 0.9358\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1698 - accuracy: 0.9541\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1573 - accuracy: 0.9358\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1770 - accuracy: 0.9312\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 0.1100 - accuracy: 0.9679\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1218 - accuracy: 0.9587\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0843 - accuracy: 0.9679\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0457 - accuracy: 0.9862\n",
      "apply_standard_scaling\n",
      "(71, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(71, 28, 6)\n",
      "5/5 [==============================] - 1s 24ms/step\n",
      "fold_acc 0.5774650.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(223, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(223, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(223, 28, 6)\n",
      "check scaled shape\n",
      "(223, 28, 6)\n",
      "(223, 28, 6)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 28, 32)       192         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_12 (MaxPooling1D  (None, 28, 6)       0           ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 28, 32)       3072        ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 28, 32)       7168        ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 28, 32)       11264       ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 28, 32)       23552       ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_93 (Conv1D)             (None, 28, 32)       29696       ['conv1d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_94 (Conv1D)             (None, 28, 32)       192         ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 28, 192)      0           ['conv1d_89[0][0]',              \n",
      "                                                                  'conv1d_90[0][0]',              \n",
      "                                                                  'conv1d_91[0][0]',              \n",
      "                                                                  'conv1d_92[0][0]',              \n",
      "                                                                  'conv1d_93[0][0]',              \n",
      "                                                                  'conv1d_94[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 28, 192)     768         ['concatenate_12[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 28, 192)      0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_95 (Conv1D)             (None, 28, 32)       6144        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 28, 192)     0           ['activation_16[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_96 (Conv1D)             (None, 28, 32)       3072        ['conv1d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_97 (Conv1D)             (None, 28, 32)       7168        ['conv1d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_98 (Conv1D)             (None, 28, 32)       11264       ['conv1d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_99 (Conv1D)             (None, 28, 32)       23552       ['conv1d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_100 (Conv1D)            (None, 28, 32)       29696       ['conv1d_95[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_101 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 28, 192)      0           ['conv1d_96[0][0]',              \n",
      "                                                                  'conv1d_97[0][0]',              \n",
      "                                                                  'conv1d_98[0][0]',              \n",
      "                                                                  'conv1d_99[0][0]',              \n",
      "                                                                  'conv1d_100[0][0]',             \n",
      "                                                                  'conv1d_101[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 28, 192)     768         ['concatenate_13[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 28, 192)      0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_102 (Conv1D)            (None, 28, 32)       6144        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_14 (MaxPooling1D  (None, 28, 192)     0           ['activation_17[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_103 (Conv1D)            (None, 28, 32)       3072        ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_104 (Conv1D)            (None, 28, 32)       7168        ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_105 (Conv1D)            (None, 28, 32)       11264       ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_106 (Conv1D)            (None, 28, 32)       23552       ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_107 (Conv1D)            (None, 28, 32)       29696       ['conv1d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_108 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_14[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 28, 192)      0           ['conv1d_103[0][0]',             \n",
      "                                                                  'conv1d_104[0][0]',             \n",
      "                                                                  'conv1d_105[0][0]',             \n",
      "                                                                  'conv1d_106[0][0]',             \n",
      "                                                                  'conv1d_107[0][0]',             \n",
      "                                                                  'conv1d_108[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_109 (Conv1D)            (None, 28, 192)      1152        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 28, 192)     768         ['concatenate_14[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 28, 192)     768         ['conv1d_109[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 28, 192)      0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 28, 192)      0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 28, 192)      0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_110 (Conv1D)            (None, 28, 32)       6144        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_15 (MaxPooling1D  (None, 28, 192)     0           ['activation_19[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_111 (Conv1D)            (None, 28, 32)       3072        ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_112 (Conv1D)            (None, 28, 32)       7168        ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_113 (Conv1D)            (None, 28, 32)       11264       ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_114 (Conv1D)            (None, 28, 32)       23552       ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_115 (Conv1D)            (None, 28, 32)       29696       ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_116 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_15[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 28, 192)      0           ['conv1d_111[0][0]',             \n",
      "                                                                  'conv1d_112[0][0]',             \n",
      "                                                                  'conv1d_113[0][0]',             \n",
      "                                                                  'conv1d_114[0][0]',             \n",
      "                                                                  'conv1d_115[0][0]',             \n",
      "                                                                  'conv1d_116[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 28, 192)     768         ['concatenate_15[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 28, 192)      0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_117 (Conv1D)            (None, 28, 32)       6144        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_16 (MaxPooling1D  (None, 28, 192)     0           ['activation_20[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_118 (Conv1D)            (None, 28, 32)       3072        ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_119 (Conv1D)            (None, 28, 32)       7168        ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_120 (Conv1D)            (None, 28, 32)       11264       ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_121 (Conv1D)            (None, 28, 32)       23552       ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_122 (Conv1D)            (None, 28, 32)       29696       ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_123 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_16[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 28, 192)      0           ['conv1d_118[0][0]',             \n",
      "                                                                  'conv1d_119[0][0]',             \n",
      "                                                                  'conv1d_120[0][0]',             \n",
      "                                                                  'conv1d_121[0][0]',             \n",
      "                                                                  'conv1d_122[0][0]',             \n",
      "                                                                  'conv1d_123[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 28, 192)     768         ['concatenate_16[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 28, 192)      0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_124 (Conv1D)            (None, 28, 32)       6144        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_17 (MaxPooling1D  (None, 28, 192)     0           ['activation_21[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_125 (Conv1D)            (None, 28, 32)       3072        ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_126 (Conv1D)            (None, 28, 32)       7168        ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_127 (Conv1D)            (None, 28, 32)       11264       ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_128 (Conv1D)            (None, 28, 32)       23552       ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_129 (Conv1D)            (None, 28, 32)       29696       ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_130 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_17[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 28, 192)      0           ['conv1d_125[0][0]',             \n",
      "                                                                  'conv1d_126[0][0]',             \n",
      "                                                                  'conv1d_127[0][0]',             \n",
      "                                                                  'conv1d_128[0][0]',             \n",
      "                                                                  'conv1d_129[0][0]',             \n",
      "                                                                  'conv1d_130[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_131 (Conv1D)            (None, 28, 192)      36864       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 28, 192)     768         ['concatenate_17[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 28, 192)     768         ['conv1d_131[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 28, 192)      0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 28, 192)      0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 28, 192)      0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 192)         0           ['activation_23[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            386         ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 105ms/step - loss: 0.9014 - accuracy: 0.5561\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.5930 - accuracy: 0.6726\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.5422 - accuracy: 0.7399\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.5262 - accuracy: 0.7354\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.3706 - accuracy: 0.8296\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.3531 - accuracy: 0.8430\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2406 - accuracy: 0.9283\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2201 - accuracy: 0.9148\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2765 - accuracy: 0.8789\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.2500 - accuracy: 0.9058\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.1676 - accuracy: 0.9507\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.1590 - accuracy: 0.9462\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0911 - accuracy: 0.9731\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.0513 - accuracy: 0.9865\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 0.0449 - accuracy: 0.9910\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0279 - accuracy: 0.9955\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0182 - accuracy: 0.9955\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0380 - accuracy: 0.9821\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0233 - accuracy: 0.9955\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "apply_standard_scaling\n",
      "(66, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(66, 28, 6)\n",
      "5/5 [==============================] - 1s 21ms/step\n",
      "fold_acc 0.5757580.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(211, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(211, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(211, 28, 6)\n",
      "check scaled shape\n",
      "(211, 28, 6)\n",
      "(211, 28, 6)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_132 (Conv1D)            (None, 28, 32)       192         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_18 (MaxPooling1D  (None, 28, 6)       0           ['input_4[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_133 (Conv1D)            (None, 28, 32)       3072        ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_134 (Conv1D)            (None, 28, 32)       7168        ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_135 (Conv1D)            (None, 28, 32)       11264       ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_136 (Conv1D)            (None, 28, 32)       23552       ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_137 (Conv1D)            (None, 28, 32)       29696       ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_138 (Conv1D)            (None, 28, 32)       192         ['max_pooling1d_18[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 28, 192)      0           ['conv1d_133[0][0]',             \n",
      "                                                                  'conv1d_134[0][0]',             \n",
      "                                                                  'conv1d_135[0][0]',             \n",
      "                                                                  'conv1d_136[0][0]',             \n",
      "                                                                  'conv1d_137[0][0]',             \n",
      "                                                                  'conv1d_138[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 28, 192)     768         ['concatenate_18[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 28, 192)      0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_139 (Conv1D)            (None, 28, 32)       6144        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_19 (MaxPooling1D  (None, 28, 192)     0           ['activation_24[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_140 (Conv1D)            (None, 28, 32)       3072        ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_141 (Conv1D)            (None, 28, 32)       7168        ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_142 (Conv1D)            (None, 28, 32)       11264       ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_143 (Conv1D)            (None, 28, 32)       23552       ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_144 (Conv1D)            (None, 28, 32)       29696       ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_145 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_19[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 28, 192)      0           ['conv1d_140[0][0]',             \n",
      "                                                                  'conv1d_141[0][0]',             \n",
      "                                                                  'conv1d_142[0][0]',             \n",
      "                                                                  'conv1d_143[0][0]',             \n",
      "                                                                  'conv1d_144[0][0]',             \n",
      "                                                                  'conv1d_145[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 28, 192)     768         ['concatenate_19[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 28, 192)      0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_146 (Conv1D)            (None, 28, 32)       6144        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_20 (MaxPooling1D  (None, 28, 192)     0           ['activation_25[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_147 (Conv1D)            (None, 28, 32)       3072        ['conv1d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_148 (Conv1D)            (None, 28, 32)       7168        ['conv1d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_149 (Conv1D)            (None, 28, 32)       11264       ['conv1d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_150 (Conv1D)            (None, 28, 32)       23552       ['conv1d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_151 (Conv1D)            (None, 28, 32)       29696       ['conv1d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_152 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_20[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 28, 192)      0           ['conv1d_147[0][0]',             \n",
      "                                                                  'conv1d_148[0][0]',             \n",
      "                                                                  'conv1d_149[0][0]',             \n",
      "                                                                  'conv1d_150[0][0]',             \n",
      "                                                                  'conv1d_151[0][0]',             \n",
      "                                                                  'conv1d_152[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_153 (Conv1D)            (None, 28, 192)      1152        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 28, 192)     768         ['concatenate_20[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 28, 192)     768         ['conv1d_153[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 28, 192)      0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 28, 192)      0           ['batch_normalization_27[0][0]', \n",
      "                                                                  'activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 28, 192)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_154 (Conv1D)            (None, 28, 32)       6144        ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_21 (MaxPooling1D  (None, 28, 192)     0           ['activation_27[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_155 (Conv1D)            (None, 28, 32)       3072        ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_156 (Conv1D)            (None, 28, 32)       7168        ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_157 (Conv1D)            (None, 28, 32)       11264       ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_158 (Conv1D)            (None, 28, 32)       23552       ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_159 (Conv1D)            (None, 28, 32)       29696       ['conv1d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_160 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_21[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 28, 192)      0           ['conv1d_155[0][0]',             \n",
      "                                                                  'conv1d_156[0][0]',             \n",
      "                                                                  'conv1d_157[0][0]',             \n",
      "                                                                  'conv1d_158[0][0]',             \n",
      "                                                                  'conv1d_159[0][0]',             \n",
      "                                                                  'conv1d_160[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 28, 192)     768         ['concatenate_21[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 28, 192)      0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_161 (Conv1D)            (None, 28, 32)       6144        ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_22 (MaxPooling1D  (None, 28, 192)     0           ['activation_28[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_162 (Conv1D)            (None, 28, 32)       3072        ['conv1d_161[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_163 (Conv1D)            (None, 28, 32)       7168        ['conv1d_161[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_164 (Conv1D)            (None, 28, 32)       11264       ['conv1d_161[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_165 (Conv1D)            (None, 28, 32)       23552       ['conv1d_161[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_166 (Conv1D)            (None, 28, 32)       29696       ['conv1d_161[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_167 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_22[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 28, 192)      0           ['conv1d_162[0][0]',             \n",
      "                                                                  'conv1d_163[0][0]',             \n",
      "                                                                  'conv1d_164[0][0]',             \n",
      "                                                                  'conv1d_165[0][0]',             \n",
      "                                                                  'conv1d_166[0][0]',             \n",
      "                                                                  'conv1d_167[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 28, 192)     768         ['concatenate_22[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 28, 192)      0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_168 (Conv1D)            (None, 28, 32)       6144        ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_23 (MaxPooling1D  (None, 28, 192)     0           ['activation_29[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_169 (Conv1D)            (None, 28, 32)       3072        ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_170 (Conv1D)            (None, 28, 32)       7168        ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_171 (Conv1D)            (None, 28, 32)       11264       ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_172 (Conv1D)            (None, 28, 32)       23552       ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_173 (Conv1D)            (None, 28, 32)       29696       ['conv1d_168[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_174 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_23[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 28, 192)      0           ['conv1d_169[0][0]',             \n",
      "                                                                  'conv1d_170[0][0]',             \n",
      "                                                                  'conv1d_171[0][0]',             \n",
      "                                                                  'conv1d_172[0][0]',             \n",
      "                                                                  'conv1d_173[0][0]',             \n",
      "                                                                  'conv1d_174[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_175 (Conv1D)            (None, 28, 192)      36864       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 28, 192)     768         ['concatenate_23[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 28, 192)     768         ['conv1d_175[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 28, 192)      0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 28, 192)      0           ['batch_normalization_31[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 28, 192)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 192)         0           ['activation_31[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            386         ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 86ms/step - loss: 0.7947 - accuracy: 0.5782\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.8033 - accuracy: 0.5450\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.7180 - accuracy: 0.6256\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.6511 - accuracy: 0.6493\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.5831 - accuracy: 0.6919\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.5046 - accuracy: 0.7204\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.5290 - accuracy: 0.7251\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.4682 - accuracy: 0.7441\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 92ms/step - loss: 0.4451 - accuracy: 0.7962\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.3764 - accuracy: 0.8389\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.3968 - accuracy: 0.8104\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.3128 - accuracy: 0.8815\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2899 - accuracy: 0.8910\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2164 - accuracy: 0.9194\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2307 - accuracy: 0.9147\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1904 - accuracy: 0.9336\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1936 - accuracy: 0.9336\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.0722 - accuracy: 0.9858\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1137 - accuracy: 0.9573\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.2021 - accuracy: 0.9384\n",
      "apply_standard_scaling\n",
      "(78, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(78, 28, 6)\n",
      "5/5 [==============================] - 1s 27ms/step\n",
      "fold_acc 0.5384620.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list_shap_deep):4\n",
      "len(list_shap_grad):4\n",
      "StratifiedGroupKFold(n_splits=4, random_state=None, shuffle=True)\n",
      "repeat: 2/2\n",
      "get_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(218, 28, 6)\n",
      "check scaled shape\n",
      "(218, 28, 6)\n",
      "(218, 28, 6)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_176 (Conv1D)            (None, 28, 32)       192         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_24 (MaxPooling1D  (None, 28, 6)       0           ['input_5[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_177 (Conv1D)            (None, 28, 32)       3072        ['conv1d_176[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_178 (Conv1D)            (None, 28, 32)       7168        ['conv1d_176[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_179 (Conv1D)            (None, 28, 32)       11264       ['conv1d_176[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_180 (Conv1D)            (None, 28, 32)       23552       ['conv1d_176[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_181 (Conv1D)            (None, 28, 32)       29696       ['conv1d_176[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_182 (Conv1D)            (None, 28, 32)       192         ['max_pooling1d_24[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 28, 192)      0           ['conv1d_177[0][0]',             \n",
      "                                                                  'conv1d_178[0][0]',             \n",
      "                                                                  'conv1d_179[0][0]',             \n",
      "                                                                  'conv1d_180[0][0]',             \n",
      "                                                                  'conv1d_181[0][0]',             \n",
      "                                                                  'conv1d_182[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 28, 192)     768         ['concatenate_24[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 28, 192)      0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_183 (Conv1D)            (None, 28, 32)       6144        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_25 (MaxPooling1D  (None, 28, 192)     0           ['activation_32[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_184 (Conv1D)            (None, 28, 32)       3072        ['conv1d_183[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_185 (Conv1D)            (None, 28, 32)       7168        ['conv1d_183[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_186 (Conv1D)            (None, 28, 32)       11264       ['conv1d_183[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_187 (Conv1D)            (None, 28, 32)       23552       ['conv1d_183[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_188 (Conv1D)            (None, 28, 32)       29696       ['conv1d_183[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_189 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_25[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 28, 192)      0           ['conv1d_184[0][0]',             \n",
      "                                                                  'conv1d_185[0][0]',             \n",
      "                                                                  'conv1d_186[0][0]',             \n",
      "                                                                  'conv1d_187[0][0]',             \n",
      "                                                                  'conv1d_188[0][0]',             \n",
      "                                                                  'conv1d_189[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 28, 192)     768         ['concatenate_25[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 28, 192)      0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_190 (Conv1D)            (None, 28, 32)       6144        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_26 (MaxPooling1D  (None, 28, 192)     0           ['activation_33[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_191 (Conv1D)            (None, 28, 32)       3072        ['conv1d_190[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_192 (Conv1D)            (None, 28, 32)       7168        ['conv1d_190[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_193 (Conv1D)            (None, 28, 32)       11264       ['conv1d_190[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_194 (Conv1D)            (None, 28, 32)       23552       ['conv1d_190[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_195 (Conv1D)            (None, 28, 32)       29696       ['conv1d_190[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_196 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_26[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 28, 192)      0           ['conv1d_191[0][0]',             \n",
      "                                                                  'conv1d_192[0][0]',             \n",
      "                                                                  'conv1d_193[0][0]',             \n",
      "                                                                  'conv1d_194[0][0]',             \n",
      "                                                                  'conv1d_195[0][0]',             \n",
      "                                                                  'conv1d_196[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_197 (Conv1D)            (None, 28, 192)      1152        ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 28, 192)     768         ['concatenate_26[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 28, 192)     768         ['conv1d_197[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 28, 192)      0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 28, 192)      0           ['batch_normalization_35[0][0]', \n",
      "                                                                  'activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 28, 192)      0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_198 (Conv1D)            (None, 28, 32)       6144        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_27 (MaxPooling1D  (None, 28, 192)     0           ['activation_35[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_199 (Conv1D)            (None, 28, 32)       3072        ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_200 (Conv1D)            (None, 28, 32)       7168        ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_201 (Conv1D)            (None, 28, 32)       11264       ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_202 (Conv1D)            (None, 28, 32)       23552       ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_203 (Conv1D)            (None, 28, 32)       29696       ['conv1d_198[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_204 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_27[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 28, 192)      0           ['conv1d_199[0][0]',             \n",
      "                                                                  'conv1d_200[0][0]',             \n",
      "                                                                  'conv1d_201[0][0]',             \n",
      "                                                                  'conv1d_202[0][0]',             \n",
      "                                                                  'conv1d_203[0][0]',             \n",
      "                                                                  'conv1d_204[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 28, 192)     768         ['concatenate_27[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 28, 192)      0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_205 (Conv1D)            (None, 28, 32)       6144        ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_28 (MaxPooling1D  (None, 28, 192)     0           ['activation_36[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_206 (Conv1D)            (None, 28, 32)       3072        ['conv1d_205[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_207 (Conv1D)            (None, 28, 32)       7168        ['conv1d_205[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_208 (Conv1D)            (None, 28, 32)       11264       ['conv1d_205[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_209 (Conv1D)            (None, 28, 32)       23552       ['conv1d_205[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_210 (Conv1D)            (None, 28, 32)       29696       ['conv1d_205[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_211 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_28[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 28, 192)      0           ['conv1d_206[0][0]',             \n",
      "                                                                  'conv1d_207[0][0]',             \n",
      "                                                                  'conv1d_208[0][0]',             \n",
      "                                                                  'conv1d_209[0][0]',             \n",
      "                                                                  'conv1d_210[0][0]',             \n",
      "                                                                  'conv1d_211[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 28, 192)     768         ['concatenate_28[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 28, 192)      0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_212 (Conv1D)            (None, 28, 32)       6144        ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_29 (MaxPooling1D  (None, 28, 192)     0           ['activation_37[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_213 (Conv1D)            (None, 28, 32)       3072        ['conv1d_212[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_214 (Conv1D)            (None, 28, 32)       7168        ['conv1d_212[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_215 (Conv1D)            (None, 28, 32)       11264       ['conv1d_212[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_216 (Conv1D)            (None, 28, 32)       23552       ['conv1d_212[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_217 (Conv1D)            (None, 28, 32)       29696       ['conv1d_212[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_218 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_29[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 28, 192)      0           ['conv1d_213[0][0]',             \n",
      "                                                                  'conv1d_214[0][0]',             \n",
      "                                                                  'conv1d_215[0][0]',             \n",
      "                                                                  'conv1d_216[0][0]',             \n",
      "                                                                  'conv1d_217[0][0]',             \n",
      "                                                                  'conv1d_218[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_219 (Conv1D)            (None, 28, 192)      36864       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 28, 192)     768         ['concatenate_29[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 28, 192)     768         ['conv1d_219[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 28, 192)      0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 28, 192)      0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 28, 192)      0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 192)         0           ['activation_39[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            386         ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 87ms/step - loss: 0.9315 - accuracy: 0.6239\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.6881 - accuracy: 0.6422\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.6017 - accuracy: 0.6789\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.5327 - accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.5036 - accuracy: 0.7752\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.4575 - accuracy: 0.7936\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 94ms/step - loss: 0.4618 - accuracy: 0.7798\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3285 - accuracy: 0.8394\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3218 - accuracy: 0.8578\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3149 - accuracy: 0.8807\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2179 - accuracy: 0.9220\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2016 - accuracy: 0.9312\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2610 - accuracy: 0.8807\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2005 - accuracy: 0.9312\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1347 - accuracy: 0.9495\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0845 - accuracy: 0.9771\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1023 - accuracy: 0.9587\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1445 - accuracy: 0.9587\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1229 - accuracy: 0.9587\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0836 - accuracy: 0.9633\n",
      "apply_standard_scaling\n",
      "(71, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(71, 28, 6)\n",
      "5/5 [==============================] - 1s 24ms/step\n",
      "fold_acc 0.5633800.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(218, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(218, 28, 6)\n",
      "check scaled shape\n",
      "(218, 28, 6)\n",
      "(218, 28, 6)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_220 (Conv1D)            (None, 28, 32)       192         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_30 (MaxPooling1D  (None, 28, 6)       0           ['input_6[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_221 (Conv1D)            (None, 28, 32)       3072        ['conv1d_220[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_222 (Conv1D)            (None, 28, 32)       7168        ['conv1d_220[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_223 (Conv1D)            (None, 28, 32)       11264       ['conv1d_220[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_224 (Conv1D)            (None, 28, 32)       23552       ['conv1d_220[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_225 (Conv1D)            (None, 28, 32)       29696       ['conv1d_220[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_226 (Conv1D)            (None, 28, 32)       192         ['max_pooling1d_30[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 28, 192)      0           ['conv1d_221[0][0]',             \n",
      "                                                                  'conv1d_222[0][0]',             \n",
      "                                                                  'conv1d_223[0][0]',             \n",
      "                                                                  'conv1d_224[0][0]',             \n",
      "                                                                  'conv1d_225[0][0]',             \n",
      "                                                                  'conv1d_226[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 28, 192)     768         ['concatenate_30[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 28, 192)      0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_227 (Conv1D)            (None, 28, 32)       6144        ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_31 (MaxPooling1D  (None, 28, 192)     0           ['activation_40[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_228 (Conv1D)            (None, 28, 32)       3072        ['conv1d_227[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_229 (Conv1D)            (None, 28, 32)       7168        ['conv1d_227[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_230 (Conv1D)            (None, 28, 32)       11264       ['conv1d_227[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_231 (Conv1D)            (None, 28, 32)       23552       ['conv1d_227[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_232 (Conv1D)            (None, 28, 32)       29696       ['conv1d_227[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_233 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_31[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 28, 192)      0           ['conv1d_228[0][0]',             \n",
      "                                                                  'conv1d_229[0][0]',             \n",
      "                                                                  'conv1d_230[0][0]',             \n",
      "                                                                  'conv1d_231[0][0]',             \n",
      "                                                                  'conv1d_232[0][0]',             \n",
      "                                                                  'conv1d_233[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 28, 192)     768         ['concatenate_31[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 28, 192)      0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_234 (Conv1D)            (None, 28, 32)       6144        ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_32 (MaxPooling1D  (None, 28, 192)     0           ['activation_41[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_235 (Conv1D)            (None, 28, 32)       3072        ['conv1d_234[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_236 (Conv1D)            (None, 28, 32)       7168        ['conv1d_234[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_237 (Conv1D)            (None, 28, 32)       11264       ['conv1d_234[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_238 (Conv1D)            (None, 28, 32)       23552       ['conv1d_234[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_239 (Conv1D)            (None, 28, 32)       29696       ['conv1d_234[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_240 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_32[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 28, 192)      0           ['conv1d_235[0][0]',             \n",
      "                                                                  'conv1d_236[0][0]',             \n",
      "                                                                  'conv1d_237[0][0]',             \n",
      "                                                                  'conv1d_238[0][0]',             \n",
      "                                                                  'conv1d_239[0][0]',             \n",
      "                                                                  'conv1d_240[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_241 (Conv1D)            (None, 28, 192)      1152        ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 28, 192)     768         ['concatenate_32[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 28, 192)     768         ['conv1d_241[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 28, 192)      0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 28, 192)      0           ['batch_normalization_43[0][0]', \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 28, 192)      0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_242 (Conv1D)            (None, 28, 32)       6144        ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_33 (MaxPooling1D  (None, 28, 192)     0           ['activation_43[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_243 (Conv1D)            (None, 28, 32)       3072        ['conv1d_242[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_244 (Conv1D)            (None, 28, 32)       7168        ['conv1d_242[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_245 (Conv1D)            (None, 28, 32)       11264       ['conv1d_242[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_246 (Conv1D)            (None, 28, 32)       23552       ['conv1d_242[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_247 (Conv1D)            (None, 28, 32)       29696       ['conv1d_242[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_248 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_33[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 28, 192)      0           ['conv1d_243[0][0]',             \n",
      "                                                                  'conv1d_244[0][0]',             \n",
      "                                                                  'conv1d_245[0][0]',             \n",
      "                                                                  'conv1d_246[0][0]',             \n",
      "                                                                  'conv1d_247[0][0]',             \n",
      "                                                                  'conv1d_248[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 28, 192)     768         ['concatenate_33[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 28, 192)      0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_249 (Conv1D)            (None, 28, 32)       6144        ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_34 (MaxPooling1D  (None, 28, 192)     0           ['activation_44[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_250 (Conv1D)            (None, 28, 32)       3072        ['conv1d_249[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_251 (Conv1D)            (None, 28, 32)       7168        ['conv1d_249[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_252 (Conv1D)            (None, 28, 32)       11264       ['conv1d_249[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_253 (Conv1D)            (None, 28, 32)       23552       ['conv1d_249[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_254 (Conv1D)            (None, 28, 32)       29696       ['conv1d_249[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_255 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_34[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 28, 192)      0           ['conv1d_250[0][0]',             \n",
      "                                                                  'conv1d_251[0][0]',             \n",
      "                                                                  'conv1d_252[0][0]',             \n",
      "                                                                  'conv1d_253[0][0]',             \n",
      "                                                                  'conv1d_254[0][0]',             \n",
      "                                                                  'conv1d_255[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 28, 192)     768         ['concatenate_34[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 28, 192)      0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_256 (Conv1D)            (None, 28, 32)       6144        ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_35 (MaxPooling1D  (None, 28, 192)     0           ['activation_45[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_257 (Conv1D)            (None, 28, 32)       3072        ['conv1d_256[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_258 (Conv1D)            (None, 28, 32)       7168        ['conv1d_256[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_259 (Conv1D)            (None, 28, 32)       11264       ['conv1d_256[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_260 (Conv1D)            (None, 28, 32)       23552       ['conv1d_256[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_261 (Conv1D)            (None, 28, 32)       29696       ['conv1d_256[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_262 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_35[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 28, 192)      0           ['conv1d_257[0][0]',             \n",
      "                                                                  'conv1d_258[0][0]',             \n",
      "                                                                  'conv1d_259[0][0]',             \n",
      "                                                                  'conv1d_260[0][0]',             \n",
      "                                                                  'conv1d_261[0][0]',             \n",
      "                                                                  'conv1d_262[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_263 (Conv1D)            (None, 28, 192)      36864       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 28, 192)     768         ['concatenate_35[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 28, 192)     768         ['conv1d_263[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 28, 192)      0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 28, 192)      0           ['batch_normalization_47[0][0]', \n",
      "                                                                  'activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 28, 192)      0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 192)         0           ['activation_47[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            386         ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 87ms/step - loss: 0.8445 - accuracy: 0.5229\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.6495 - accuracy: 0.6560\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.5737 - accuracy: 0.6789\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.5852 - accuracy: 0.7385\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.4395 - accuracy: 0.8119\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3645 - accuracy: 0.8532\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.2697 - accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3185 - accuracy: 0.8532\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.1807 - accuracy: 0.9358\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1215 - accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.1360 - accuracy: 0.9495\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0996 - accuracy: 0.9725\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0679 - accuracy: 0.9908\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0849 - accuracy: 0.9817\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0892 - accuracy: 0.9771\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0520 - accuracy: 0.9862\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.0587 - accuracy: 0.9862\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0679 - accuracy: 0.9817\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0870 - accuracy: 0.9725\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0581 - accuracy: 0.9862\n",
      "apply_standard_scaling\n",
      "(71, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(71, 28, 6)\n",
      "5/5 [==============================] - 1s 23ms/step\n",
      "fold_acc 0.5633800.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(216, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(216, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(216, 28, 6)\n",
      "check scaled shape\n",
      "(216, 28, 6)\n",
      "(216, 28, 6)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_264 (Conv1D)            (None, 28, 32)       192         ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_36 (MaxPooling1D  (None, 28, 6)       0           ['input_7[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_265 (Conv1D)            (None, 28, 32)       3072        ['conv1d_264[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_266 (Conv1D)            (None, 28, 32)       7168        ['conv1d_264[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_267 (Conv1D)            (None, 28, 32)       11264       ['conv1d_264[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_268 (Conv1D)            (None, 28, 32)       23552       ['conv1d_264[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_269 (Conv1D)            (None, 28, 32)       29696       ['conv1d_264[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_270 (Conv1D)            (None, 28, 32)       192         ['max_pooling1d_36[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 28, 192)      0           ['conv1d_265[0][0]',             \n",
      "                                                                  'conv1d_266[0][0]',             \n",
      "                                                                  'conv1d_267[0][0]',             \n",
      "                                                                  'conv1d_268[0][0]',             \n",
      "                                                                  'conv1d_269[0][0]',             \n",
      "                                                                  'conv1d_270[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 28, 192)     768         ['concatenate_36[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 28, 192)      0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_271 (Conv1D)            (None, 28, 32)       6144        ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_37 (MaxPooling1D  (None, 28, 192)     0           ['activation_48[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_272 (Conv1D)            (None, 28, 32)       3072        ['conv1d_271[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_273 (Conv1D)            (None, 28, 32)       7168        ['conv1d_271[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_274 (Conv1D)            (None, 28, 32)       11264       ['conv1d_271[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_275 (Conv1D)            (None, 28, 32)       23552       ['conv1d_271[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_276 (Conv1D)            (None, 28, 32)       29696       ['conv1d_271[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_277 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_37[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 28, 192)      0           ['conv1d_272[0][0]',             \n",
      "                                                                  'conv1d_273[0][0]',             \n",
      "                                                                  'conv1d_274[0][0]',             \n",
      "                                                                  'conv1d_275[0][0]',             \n",
      "                                                                  'conv1d_276[0][0]',             \n",
      "                                                                  'conv1d_277[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 28, 192)     768         ['concatenate_37[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 28, 192)      0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_278 (Conv1D)            (None, 28, 32)       6144        ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_38 (MaxPooling1D  (None, 28, 192)     0           ['activation_49[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_279 (Conv1D)            (None, 28, 32)       3072        ['conv1d_278[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_280 (Conv1D)            (None, 28, 32)       7168        ['conv1d_278[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_281 (Conv1D)            (None, 28, 32)       11264       ['conv1d_278[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_282 (Conv1D)            (None, 28, 32)       23552       ['conv1d_278[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_283 (Conv1D)            (None, 28, 32)       29696       ['conv1d_278[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_284 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_38[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 28, 192)      0           ['conv1d_279[0][0]',             \n",
      "                                                                  'conv1d_280[0][0]',             \n",
      "                                                                  'conv1d_281[0][0]',             \n",
      "                                                                  'conv1d_282[0][0]',             \n",
      "                                                                  'conv1d_283[0][0]',             \n",
      "                                                                  'conv1d_284[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_285 (Conv1D)            (None, 28, 192)      1152        ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 28, 192)     768         ['concatenate_38[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 28, 192)     768         ['conv1d_285[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 28, 192)      0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 28, 192)      0           ['batch_normalization_51[0][0]', \n",
      "                                                                  'activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 28, 192)      0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_286 (Conv1D)            (None, 28, 32)       6144        ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_39 (MaxPooling1D  (None, 28, 192)     0           ['activation_51[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_287 (Conv1D)            (None, 28, 32)       3072        ['conv1d_286[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_288 (Conv1D)            (None, 28, 32)       7168        ['conv1d_286[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_289 (Conv1D)            (None, 28, 32)       11264       ['conv1d_286[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_290 (Conv1D)            (None, 28, 32)       23552       ['conv1d_286[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_291 (Conv1D)            (None, 28, 32)       29696       ['conv1d_286[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_292 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_39[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 28, 192)      0           ['conv1d_287[0][0]',             \n",
      "                                                                  'conv1d_288[0][0]',             \n",
      "                                                                  'conv1d_289[0][0]',             \n",
      "                                                                  'conv1d_290[0][0]',             \n",
      "                                                                  'conv1d_291[0][0]',             \n",
      "                                                                  'conv1d_292[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 28, 192)     768         ['concatenate_39[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 28, 192)      0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_293 (Conv1D)            (None, 28, 32)       6144        ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_40 (MaxPooling1D  (None, 28, 192)     0           ['activation_52[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_294 (Conv1D)            (None, 28, 32)       3072        ['conv1d_293[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_295 (Conv1D)            (None, 28, 32)       7168        ['conv1d_293[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_296 (Conv1D)            (None, 28, 32)       11264       ['conv1d_293[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_297 (Conv1D)            (None, 28, 32)       23552       ['conv1d_293[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_298 (Conv1D)            (None, 28, 32)       29696       ['conv1d_293[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_299 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_40[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 28, 192)      0           ['conv1d_294[0][0]',             \n",
      "                                                                  'conv1d_295[0][0]',             \n",
      "                                                                  'conv1d_296[0][0]',             \n",
      "                                                                  'conv1d_297[0][0]',             \n",
      "                                                                  'conv1d_298[0][0]',             \n",
      "                                                                  'conv1d_299[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 28, 192)     768         ['concatenate_40[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 28, 192)      0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_300 (Conv1D)            (None, 28, 32)       6144        ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_41 (MaxPooling1D  (None, 28, 192)     0           ['activation_53[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_301 (Conv1D)            (None, 28, 32)       3072        ['conv1d_300[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_302 (Conv1D)            (None, 28, 32)       7168        ['conv1d_300[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_303 (Conv1D)            (None, 28, 32)       11264       ['conv1d_300[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_304 (Conv1D)            (None, 28, 32)       23552       ['conv1d_300[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_305 (Conv1D)            (None, 28, 32)       29696       ['conv1d_300[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_306 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_41[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 28, 192)      0           ['conv1d_301[0][0]',             \n",
      "                                                                  'conv1d_302[0][0]',             \n",
      "                                                                  'conv1d_303[0][0]',             \n",
      "                                                                  'conv1d_304[0][0]',             \n",
      "                                                                  'conv1d_305[0][0]',             \n",
      "                                                                  'conv1d_306[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_307 (Conv1D)            (None, 28, 192)      36864       ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 28, 192)     768         ['concatenate_41[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 28, 192)     768         ['conv1d_307[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 28, 192)      0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 28, 192)      0           ['batch_normalization_55[0][0]', \n",
      "                                                                  'activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 28, 192)      0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 192)         0           ['activation_55[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2)            386         ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 86ms/step - loss: 1.0594 - accuracy: 0.5231\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.6774 - accuracy: 0.6713\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.5499 - accuracy: 0.7315\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.5763 - accuracy: 0.7130\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.5588 - accuracy: 0.6852\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.4797 - accuracy: 0.7685\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.3921 - accuracy: 0.8380\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.3096 - accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2800 - accuracy: 0.8935\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 0.2214 - accuracy: 0.9120\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2086 - accuracy: 0.9074\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2127 - accuracy: 0.9167\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2267 - accuracy: 0.9213\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1331 - accuracy: 0.9537\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2073 - accuracy: 0.9167\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1135 - accuracy: 0.9722\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0588 - accuracy: 0.9907\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0389 - accuracy: 0.9954\n",
      "apply_standard_scaling\n",
      "(73, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(73, 28, 6)\n",
      "5/5 [==============================] - 1s 23ms/step\n",
      "fold_acc 0.5342470.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standard_scaling\n",
      "(215, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "apply_standard_scaling\n",
      "(215, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(215, 28, 6)\n",
      "check scaled shape\n",
      "(215, 28, 6)\n",
      "(215, 28, 6)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 28, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_308 (Conv1D)            (None, 28, 32)       192         ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_42 (MaxPooling1D  (None, 28, 6)       0           ['input_8[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_309 (Conv1D)            (None, 28, 32)       3072        ['conv1d_308[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_310 (Conv1D)            (None, 28, 32)       7168        ['conv1d_308[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_311 (Conv1D)            (None, 28, 32)       11264       ['conv1d_308[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_312 (Conv1D)            (None, 28, 32)       23552       ['conv1d_308[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_313 (Conv1D)            (None, 28, 32)       29696       ['conv1d_308[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_314 (Conv1D)            (None, 28, 32)       192         ['max_pooling1d_42[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 28, 192)      0           ['conv1d_309[0][0]',             \n",
      "                                                                  'conv1d_310[0][0]',             \n",
      "                                                                  'conv1d_311[0][0]',             \n",
      "                                                                  'conv1d_312[0][0]',             \n",
      "                                                                  'conv1d_313[0][0]',             \n",
      "                                                                  'conv1d_314[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 28, 192)     768         ['concatenate_42[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 28, 192)      0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_315 (Conv1D)            (None, 28, 32)       6144        ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_43 (MaxPooling1D  (None, 28, 192)     0           ['activation_56[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_316 (Conv1D)            (None, 28, 32)       3072        ['conv1d_315[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_317 (Conv1D)            (None, 28, 32)       7168        ['conv1d_315[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_318 (Conv1D)            (None, 28, 32)       11264       ['conv1d_315[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_319 (Conv1D)            (None, 28, 32)       23552       ['conv1d_315[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_320 (Conv1D)            (None, 28, 32)       29696       ['conv1d_315[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_321 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_43[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 28, 192)      0           ['conv1d_316[0][0]',             \n",
      "                                                                  'conv1d_317[0][0]',             \n",
      "                                                                  'conv1d_318[0][0]',             \n",
      "                                                                  'conv1d_319[0][0]',             \n",
      "                                                                  'conv1d_320[0][0]',             \n",
      "                                                                  'conv1d_321[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 28, 192)     768         ['concatenate_43[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 28, 192)      0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_322 (Conv1D)            (None, 28, 32)       6144        ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_44 (MaxPooling1D  (None, 28, 192)     0           ['activation_57[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_323 (Conv1D)            (None, 28, 32)       3072        ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_324 (Conv1D)            (None, 28, 32)       7168        ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_325 (Conv1D)            (None, 28, 32)       11264       ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_326 (Conv1D)            (None, 28, 32)       23552       ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_327 (Conv1D)            (None, 28, 32)       29696       ['conv1d_322[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_328 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_44[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 28, 192)      0           ['conv1d_323[0][0]',             \n",
      "                                                                  'conv1d_324[0][0]',             \n",
      "                                                                  'conv1d_325[0][0]',             \n",
      "                                                                  'conv1d_326[0][0]',             \n",
      "                                                                  'conv1d_327[0][0]',             \n",
      "                                                                  'conv1d_328[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_329 (Conv1D)            (None, 28, 192)      1152        ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 28, 192)     768         ['concatenate_44[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 28, 192)     768         ['conv1d_329[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 28, 192)      0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 28, 192)      0           ['batch_normalization_59[0][0]', \n",
      "                                                                  'activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 28, 192)      0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_330 (Conv1D)            (None, 28, 32)       6144        ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_45 (MaxPooling1D  (None, 28, 192)     0           ['activation_59[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_331 (Conv1D)            (None, 28, 32)       3072        ['conv1d_330[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_332 (Conv1D)            (None, 28, 32)       7168        ['conv1d_330[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_333 (Conv1D)            (None, 28, 32)       11264       ['conv1d_330[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_334 (Conv1D)            (None, 28, 32)       23552       ['conv1d_330[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_335 (Conv1D)            (None, 28, 32)       29696       ['conv1d_330[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_336 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_45[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 28, 192)      0           ['conv1d_331[0][0]',             \n",
      "                                                                  'conv1d_332[0][0]',             \n",
      "                                                                  'conv1d_333[0][0]',             \n",
      "                                                                  'conv1d_334[0][0]',             \n",
      "                                                                  'conv1d_335[0][0]',             \n",
      "                                                                  'conv1d_336[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 28, 192)     768         ['concatenate_45[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 28, 192)      0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_337 (Conv1D)            (None, 28, 32)       6144        ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_46 (MaxPooling1D  (None, 28, 192)     0           ['activation_60[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_338 (Conv1D)            (None, 28, 32)       3072        ['conv1d_337[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_339 (Conv1D)            (None, 28, 32)       7168        ['conv1d_337[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_340 (Conv1D)            (None, 28, 32)       11264       ['conv1d_337[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_341 (Conv1D)            (None, 28, 32)       23552       ['conv1d_337[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_342 (Conv1D)            (None, 28, 32)       29696       ['conv1d_337[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_343 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_46[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 28, 192)      0           ['conv1d_338[0][0]',             \n",
      "                                                                  'conv1d_339[0][0]',             \n",
      "                                                                  'conv1d_340[0][0]',             \n",
      "                                                                  'conv1d_341[0][0]',             \n",
      "                                                                  'conv1d_342[0][0]',             \n",
      "                                                                  'conv1d_343[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 28, 192)     768         ['concatenate_46[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 28, 192)      0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_344 (Conv1D)            (None, 28, 32)       6144        ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling1d_47 (MaxPooling1D  (None, 28, 192)     0           ['activation_61[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_345 (Conv1D)            (None, 28, 32)       3072        ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_346 (Conv1D)            (None, 28, 32)       7168        ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_347 (Conv1D)            (None, 28, 32)       11264       ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_348 (Conv1D)            (None, 28, 32)       23552       ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_349 (Conv1D)            (None, 28, 32)       29696       ['conv1d_344[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_350 (Conv1D)            (None, 28, 32)       6144        ['max_pooling1d_47[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 28, 192)      0           ['conv1d_345[0][0]',             \n",
      "                                                                  'conv1d_346[0][0]',             \n",
      "                                                                  'conv1d_347[0][0]',             \n",
      "                                                                  'conv1d_348[0][0]',             \n",
      "                                                                  'conv1d_349[0][0]',             \n",
      "                                                                  'conv1d_350[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_351 (Conv1D)            (None, 28, 192)      36864       ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 28, 192)     768         ['concatenate_47[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 28, 192)     768         ['conv1d_351[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 28, 192)      0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 28, 192)      0           ['batch_normalization_63[0][0]', \n",
      "                                                                  'activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 28, 192)      0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 192)         0           ['activation_63[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 2)            386         ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 554,882\n",
      "Trainable params: 551,810\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 85ms/step - loss: 1.0602 - accuracy: 0.5023\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.6374 - accuracy: 0.6884\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.6313 - accuracy: 0.6651\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.6577 - accuracy: 0.7070\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.5421 - accuracy: 0.7395\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.4307 - accuracy: 0.8512\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.3795 - accuracy: 0.8558\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.3364 - accuracy: 0.8558\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2340 - accuracy: 0.9349\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2277 - accuracy: 0.9116\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.2187 - accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.1589 - accuracy: 0.9302\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1425 - accuracy: 0.9488\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0712 - accuracy: 0.9721\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 0.0995 - accuracy: 0.9721\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1579 - accuracy: 0.9302\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.1204 - accuracy: 0.9814\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.0467 - accuracy: 0.9953\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 86ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "apply_standard_scaling\n",
      "(74, 28, 6)\n",
      "(6,)\n",
      "(6,)\n",
      "(74, 28, 6)\n",
      "5/5 [==============================] - 1s 25ms/step\n",
      "fold_acc 0.6351350.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list_shap_deep):8\n",
      "len(list_shap_grad):8\n"
     ]
    }
   ],
   "source": [
    "repeat_output = inceptiontime_cv_repeat(X, y, groups, features, output_it, fset, \\\n",
    "                                        use_bottleneck=use_bottleneck, \\\n",
    "                                        kernel_size=kernel_size, \\\n",
    "                                        epochs=epochs, \\\n",
    "                                        repeats=repeats, \\\n",
    "                                        job_id=job_id, \\\n",
    "                                        save_shap_values=save_shap_values, \\\n",
    "                                        verbose=verbose)\n",
    "scores, shap_lists_all = repeat_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>repeat</th>\n",
       "      <th>cv</th>\n",
       "      <th>classifier</th>\n",
       "      <th>fset</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>2.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>StratifiedGroupKFold(n_splits=4, random_state=...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>all</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1  repeat  \\\n",
       "0  0.567568   0.777778  0.446809  0.567568     1.0   \n",
       "1  0.577465   0.558824  0.558824  0.558824     1.0   \n",
       "2  0.575758   0.480000  0.444444  0.461538     1.0   \n",
       "3  0.538462   0.571429  0.800000  0.666667     1.0   \n",
       "4  0.563380   0.652174  0.394737  0.491803     2.0   \n",
       "5  0.563380   0.500000  1.000000  0.666667     2.0   \n",
       "6  0.534247   0.705882  0.292683  0.413793     2.0   \n",
       "7  0.635135   0.653846  0.790698  0.715789     2.0   \n",
       "\n",
       "                                                  cv     classifier fset  \\\n",
       "0  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "1  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "2  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "3  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "4  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "5  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "6  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "7  StratifiedGroupKFold(n_splits=4, random_state=...  InceptionTime  all   \n",
       "\n",
       "   kernel_size  epochs job_id  \n",
       "0           20      20      1  \n",
       "1           20      20      1  \n",
       "2           20      20      1  \n",
       "3           20      20      1  \n",
       "4           20      20      1  \n",
       "5           20      20      1  \n",
       "6           20      20      1  \n",
       "7           20      20      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5694242180471198\n"
     ]
    }
   ],
   "source": [
    "print(scores.accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "from cv_inceptiontime import shap2npy\n",
    "\n",
    "shap2npy(fset, shap_lists_all, output_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.npy\t list_accuracy.npy  list_idx_train.npy\tlist_shap_grad.npy\n",
      "list_X_test.npy  list_idx_test.npy  list_shap_deep.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $output_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list_idx_train.npy',\n",
       " 'list_X_test.npy',\n",
       " 'list_idx_test.npy',\n",
       " 'list_shap_deep.npy',\n",
       " 'list_accuracy.npy',\n",
       " 'list_shap_grad.npy',\n",
       " 'features.npy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir(output_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_idx_train = np.load(output_shap / 'list_idx_train.npy', allow_pickle=True)\n",
    "list_idx_test = np.load(output_shap / 'list_idx_test.npy', allow_pickle=True)\n",
    "list_X_test = np.load(output_shap / 'list_X_test.npy', allow_pickle=True)\n",
    "list_shap_deep = np.load(output_shap / 'list_shap_deep.npy', allow_pickle=True)\n",
    "list_shap_grad = np.load(output_shap / 'list_shap_grad.npy', allow_pickle=True)\n",
    "list_accuracy = np.load(output_shap / 'list_accuracy.npy', allow_pickle=True)\n",
    "features_load = np.load(output_shap / 'features.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5694242180471198\n",
      "(8,)\n",
      "(215,)\n",
      "[  2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  20  21  24\n",
      "  25  26  27  28  29  32  33  34  35  36  37  38  39  40  41  44  45  48\n",
      "  49  52  53  54  55  56  57  60  61  62  63  64  65  68  69  70  71  72\n",
      "  73  74  75  76  77  80  81  82  83  84  85  88  89  90  91  92  93  94\n",
      "  95  96  97 100 101 102 103 106 107 108 109 110 111 112 113 114 115 120\n",
      " 121 122 123 124 125 126 129 130 131 132 133 134 135 136 137 138 141 142\n",
      " 143 144 145 146 147 148 151 152 153 154 157 158 159 160 161 162 165 166\n",
      " 167 170 171 172 173 174 175 176 177 180 181 182 183 186 187 188 189 190\n",
      " 191 194 195 196 197 198 201 202 203 204 207 208 211 212 213 214 215 216\n",
      " 221 222 223 224 225 226 228 230 231 232 233 234 235 237 239 240 241 242\n",
      " 243 245 247 248 249 250 252 254 256 257 258 259 260 262 264 265 266 267\n",
      " 268 269 270 272 274 275 276 278 280 281 282 283 284 285 286 287 288]\n",
      "[  0   1  13  18  19  22  23  30  31  42  43  46  47  50  51  58  59  66\n",
      "  67  78  79  86  87  98  99 104 105 116 117 118 119 127 128 139 140 149\n",
      " 150 155 156 163 164 168 169 178 179 184 185 192 193 199 200 205 206 209\n",
      " 210 217 218 219 220 227 229 236 238 244 246 251 253 255 261 263 271 273\n",
      " 277 279]\n",
      "(8,)\n",
      "(74, 28, 6)\n",
      "(74, 28, 6)\n",
      "[[ 4.59635948e-04  1.28497423e-03 -2.65455598e-03 -3.19916721e-04\n",
      "   2.80288829e-03  4.62740853e-03]\n",
      " [ 8.61114467e-02  1.71524308e-03 -1.53851141e-03 -4.66985552e-04\n",
      "   1.97697830e-03 -3.79908023e-03]\n",
      " [ 2.85177174e-02  2.42807288e-03 -1.13524774e-03 -3.07316315e-03\n",
      "   6.10831439e-04  6.30601373e-03]\n",
      " [ 1.89474651e-02  3.23726815e-03 -5.16053734e-04  8.19823521e-04\n",
      "  -3.25703964e-03 -8.10043173e-03]\n",
      " [ 3.42745420e-04 -6.27859517e-04 -3.99736551e-04 -3.27818224e-03\n",
      "   1.10858584e-02  5.04222040e-04]\n",
      " [ 4.98626442e-02  7.78446869e-04 -1.95555797e-03 -2.70273143e-03\n",
      "   6.73958024e-04  4.99559305e-03]\n",
      " [ 8.40811998e-02  2.48744193e-03  1.39008229e-03 -1.55128785e-03\n",
      "   9.49744478e-03  3.13428453e-03]\n",
      " [ 1.59171855e-02 -3.00646789e-04 -3.88632412e-03 -2.77290474e-03\n",
      "   5.62448373e-04  1.02683516e-02]\n",
      " [ 9.97017392e-03  2.15199777e-04 -5.93882764e-03 -1.34481478e-03\n",
      "  -6.07171131e-04  1.82172047e-03]\n",
      " [-1.93036131e-02  2.34174752e-03  2.16981676e-04 -3.92527676e-03\n",
      "   3.20404148e-03  2.04627386e-03]\n",
      " [ 2.55823112e-04  1.06875773e-03 -4.61497541e-04 -2.15202128e-04\n",
      "  -5.40640897e-03  6.50742147e-03]\n",
      " [-3.01009997e-03 -1.09607527e-04 -3.34005390e-03 -3.55921180e-03\n",
      "   2.59194751e-03 -2.39799130e-03]\n",
      " [-1.30859306e-02  3.00548579e-03 -4.45032771e-03 -9.80644691e-04\n",
      "  -1.90636764e-03  1.43321923e-03]\n",
      " [ 2.29615458e-03 -1.29609315e-03 -4.42010372e-04 -2.18818528e-03\n",
      "   1.92009027e-04 -1.37097409e-03]\n",
      " [ 3.91897981e-02  2.77622133e-03 -2.91829213e-03 -2.83351900e-03\n",
      "   3.76772258e-04 -7.05044094e-04]\n",
      " [-1.03661963e-03  1.67415772e-03 -2.74752593e-03 -7.51198475e-03\n",
      "   5.78124479e-03  3.92107614e-03]\n",
      " [ 4.82363654e-02  6.49435098e-04 -2.21017965e-04 -2.09041642e-03\n",
      "   1.22933163e-04 -1.04308903e-02]\n",
      " [-1.49362027e-02  1.68632286e-03 -1.31684561e-03 -1.63449304e-03\n",
      "   2.31422588e-02  7.88356098e-03]\n",
      " [ 5.50332875e-03 -8.97901063e-05 -6.68830323e-04 -2.60032674e-03\n",
      "   1.17142021e-02 -1.92209779e-03]\n",
      " [ 1.34969865e-02  1.20158391e-03 -2.06186034e-04  1.36427374e-03\n",
      "  -3.85755128e-03  1.20076005e-02]\n",
      " [ 2.73529114e-02  4.77563980e-04  4.72976445e-06 -7.42597779e-03\n",
      "  -2.89097935e-03 -2.94143537e-03]\n",
      " [ 5.03828940e-02  2.07168704e-03  1.60785688e-04 -4.35862535e-03\n",
      "  -2.63395631e-03 -2.64636006e-03]\n",
      " [ 3.13814671e-02  1.62172466e-04 -1.31395266e-03 -1.16450001e-03\n",
      "   5.58625897e-03 -1.50673140e-03]\n",
      " [ 6.40225531e-03  5.95718870e-04 -9.38506028e-04  1.22070215e-03\n",
      "  -4.70325204e-03 -4.84057591e-03]\n",
      " [ 1.02779301e-02 -8.62853414e-04 -1.03088638e-03 -1.79291050e-03\n",
      "  -2.30653739e-03 -2.53143626e-03]\n",
      " [ 1.62821181e-02  5.09675057e-04 -2.35143150e-05 -3.34857886e-03\n",
      "   1.83752181e-02  2.29749636e-03]\n",
      " [ 1.53104789e-02  1.09251360e-03 -1.25056938e-03  2.40369725e-04\n",
      "  -3.04028579e-03  4.71376473e-03]\n",
      " [-2.89015536e-04 -6.89594414e-04 -6.17374842e-04  3.93899302e-03\n",
      "  -2.67890538e-03 -2.66702139e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(list_accuracy.mean())\n",
    "print(list_idx_train.shape)\n",
    "print(list_idx_train[0].shape)\n",
    "print(list_idx_train[0])\n",
    "print(list_idx_test[0])\n",
    "print(list_shap_deep.shape)\n",
    "print(list_shap_deep[0].shape)\n",
    "print(list_shap_grad[0].shape)\n",
    "print(list_shap_deep[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136,)\n",
      "(153,)\n"
     ]
    }
   ],
   "source": [
    "print(y[y==0].shape)\n",
    "print(y[y==1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(output_shap / 'y_mean.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = np.load('/wrk-vakka/group/lmu/projects/n_track_ML/output/shap/shap_inceptiontime/20221117135226/y_max.npy')\n",
    "y_mean = np.load('/wrk-vakka/group/lmu/projects/n_track_ML/output/shap/shap_inceptiontime/20221117140251/y_mean.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_max - y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_max - y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tsc)",
   "language": "python",
   "name": "tsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
